{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MANIC's entry to FNC-1\n",
    "\n",
    "This model was our entry into FNC-1. Read more about the competition at fakenewschallenge.org.\n",
    "\n",
    "This model placed 10th of 50 entrants with a score of 9243/11650.5\n",
    "\n",
    "First let's set the detail of our model (For our final submission we used n_estimators=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detail = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load our training data (\"train_bodies.csv\" and \"train_stances.csv\" are located in res/fnc/fnc-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset\n",
      "Total stances: 49972\n",
      "Total bodies: 1683\n"
     ]
    }
   ],
   "source": [
    "from res.fnc.utils.dataset import DataSet\n",
    "d = DataSet(path=\"res/fnc/fnc-1/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we split our data into a training set (~80%) and holdout set (~20%). The training set is split into 10 folds of ~8% each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from res.fnc.utils.generate_test_splits import kfold_split, get_stances_for_folds\n",
    "\n",
    "folds,holdout = kfold_split(d, n_folds=10)\n",
    "fold_stances, hold_out_stances = get_stances_for_folds(d, folds, holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we generate the features of our data and construct a feature vector for each headline-body pair. The feature vector has length 152."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features finished for fold  0\n",
      "Features finished for fold  1\n",
      "Features finished for fold  2\n",
      "Features finished for fold  3\n",
      "Features finished for fold  4\n",
      "Features finished for fold  5\n",
      "Features finished for fold  6\n",
      "Features finished for fold  7\n",
      "Features finished for fold  8\n",
      "Features finished for fold  9\n",
      "Features finished for holdout set\n",
      "152\n"
     ]
    }
   ],
   "source": [
    "from res.fnc.fnc_kfold import generate_features\n",
    "Xs = dict()\n",
    "ys = dict()\n",
    "\n",
    "for fold in fold_stances:\n",
    "    Xs[fold],ys[fold] = generate_features(fold_stances[fold],d,str(fold))\n",
    "    print ('Features finished for fold ', fold)\n",
    "X_holdout,y_holdout = generate_features(hold_out_stances,d,\"holdout\")\n",
    "print ('Features finished for holdout set')\n",
    "print(len(X_holdout[0]))\n",
    "#print(X_holdout[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During development we used the 10 folds for cross-validation, but we're done with development.\n",
    "\n",
    "Now let's smush all the folds together into one training set and check its score on the holdout set.\n",
    "\n",
    "First we merge the folds into one array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_arrays = [np.array(Xs[fold]) for fold in Xs]\n",
    "y_arrays = [np.array(ys[fold]) for fold in ys]\n",
    "X_train = np.concatenate(X_arrays)\n",
    "y_train = np.concatenate(y_arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train a Random Forest Classifier to seperate the data between \"Unrelated\" and \"Discuss/Disagree/Agree\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=500, n_jobs=1, oob_score=False, random_state=42,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "y_relation_train = [0 if a < 3 else 3 for a in y_train]\n",
    "relationModel = RandomForestClassifier(n_estimators=detail, random_state=42)\n",
    "relationModel.fit(X_train, y_relation_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the relation sort performs on the holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relation Sort Accuracy: 0.976\n"
     ]
    }
   ],
   "source": [
    "y_relation_holdout = [0 if y < 3 else 3 for y in y_holdout]\n",
    "score = relationModel.score(X_holdout, y_relation_holdout)\n",
    "print(\"Relation Sort Accuracy: %0.3f\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train a Random Forest Classifier to seperate the data between \"Discuss\" and \"Disagree/Agree\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=500, n_jobs=1, oob_score=False, random_state=42,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_neu_train = [x for i, x in enumerate(X_train) if y_train[i] != 3]\n",
    "y_neu_train = [0 if y < 2 else 2 for y in y_train if y != 3]\n",
    "neutralModel = RandomForestClassifier(n_estimators=detail, random_state=42)\n",
    "neutralModel.fit(X_neu_train, y_neu_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the neutrality sort performs on the holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutrality Sort Accuracy: 0.780\n"
     ]
    }
   ],
   "source": [
    "X_neu_holdout = [x for i, x in enumerate(X_holdout) if y_holdout[i] != 3]\n",
    "y_neu_holdout = [0 if y < 2 else 2 for y in y_holdout if y != 3]\n",
    "score = neutralModel.score(X_neu_holdout, y_neu_holdout)\n",
    "print(\"Neutrality Sort Accuracy: %0.3f\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train a Random Forest Classifier to seperate the data between \"Disagree\" and \"Agree\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=500, n_jobs=1, oob_score=False, random_state=42,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_train = [x for i, x in enumerate(X_train) if y_train[i] < 2]\n",
    "y_val_train = [y for y in y_train if y < 2]\n",
    "valenceModel = RandomForestClassifier(n_estimators=detail, random_state=42)\n",
    "valenceModel.fit(X_val_train, y_val_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the valence sort performs on the holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence Sort Accuracy: 0.840\n"
     ]
    }
   ],
   "source": [
    "X_val_holdout = [x for i, x in enumerate(X_holdout) if y_holdout[i] < 2]\n",
    "y_val_holdout = [y for y in y_holdout if y < 2]\n",
    "score = valenceModel.score(X_val_holdout, y_val_holdout)\n",
    "print(\"Valence Sort Accuracy: %0.3f\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's combine all three models together and see how we did!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------\n",
      "|           |   agree   | disagree  |  discuss  | unrelated |\n",
      "-------------------------------------------------------------\n",
      "|   agree   |    384    |     1     |    339    |    38     |\n",
      "-------------------------------------------------------------\n",
      "| disagree  |    71     |    15     |    66     |    10     |\n",
      "-------------------------------------------------------------\n",
      "|  discuss  |    129    |    15     |   1548    |    108    |\n",
      "-------------------------------------------------------------\n",
      "| unrelated |    10     |     0     |    64     |   6824    |\n",
      "-------------------------------------------------------------\n",
      "Score: 3808.25 out of 4448.5\t(85.6075081488142%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "85.6075081488142"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from res.fnc.utils.score import report_score, LABELS, score_submission\n",
    "\n",
    "pred_rel = relationModel.predict(X_holdout)\n",
    "pred_neu = neutralModel.predict(X_holdout)\n",
    "pred_val = valenceModel.predict(X_holdout)\n",
    "pred = [3 if pred_rel[i] == 3 else (2 if pred_neu[i] == 2 else (1 if pred_val[i] == 1 else 0)) for i in range(0, len(X_holdout))]\n",
    "\n",
    "predicted = [LABELS[int(a)] for a in pred]\n",
    "actual = [LABELS[int(a)] for a in y_holdout]\n",
    "report_score(actual,predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, fast-forward to when the FNC-1 organizers release the test data set.\n",
    "\n",
    "This time, we trained on ALL of the training data, and we'll see how we do predicting the official test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "X_arrays = [np.array(Xs[fold]) for fold in Xs]\n",
    "X_arrays.append(X_holdout)\n",
    "y_arrays = [np.array(ys[fold]) for fold in ys]\n",
    "y_arrays.append(y_holdout)\n",
    "X_train = np.concatenate(X_arrays)\n",
    "y_train = np.concatenate(y_arrays)\n",
    "\n",
    "y_rel_train = [0 if y < 3 else 3 for y in y_train]\n",
    "\n",
    "X_neu_train = [x for i, x in enumerate(X_train) if y_train[i] < 3]\n",
    "y_neu_train = [0 if y < 2 else 2 for y in y_train if y < 3]\n",
    "\n",
    "X_val_train = [x for i, x in enumerate(X_train) if y_train[i] < 2]\n",
    "y_val_train = [y for y in y_train if y < 2]\n",
    "\n",
    "relationModel = RandomForestClassifier(n_estimators=detail, random_state=42)\n",
    "neutralModel = RandomForestClassifier(n_estimators=detail, random_state=42)\n",
    "valenceModel = RandomForestClassifier(n_estimators=detail, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=500, n_jobs=1, oob_score=False, random_state=42,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relationModel.fit(X_train, y_rel_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=500, n_jobs=1, oob_score=False, random_state=42,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neutralModel.fit(X_neu_train, y_neu_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=500, n_jobs=1, oob_score=False, random_state=42,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valenceModel.fit(X_val_train, y_val_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load the official test datasets, (\"test_bodies.csv\" and \"test_stances.csv\" are in res/fnc/eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset\n",
      "Total stances: 25413\n",
      "Total bodies: 904\n"
     ]
    }
   ],
   "source": [
    "test_d = DataSet(path=\"./res/fnc/eval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we generate the feature vectors for the headline-body pairs in the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test, y_test = generate_features(test_d.stances, test_d, \"finaltrial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see our final competition score!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------\n",
      "|           |   agree   | disagree  |  discuss  | unrelated |\n",
      "-------------------------------------------------------------\n",
      "|   agree   |    502    |     1     |   1230    |    170    |\n",
      "-------------------------------------------------------------\n",
      "| disagree  |    157    |     0     |    382    |    158    |\n",
      "-------------------------------------------------------------\n",
      "|  discuss  |    358    |     2     |   3717    |    387    |\n",
      "-------------------------------------------------------------\n",
      "| unrelated |    32     |     0     |    300    |   18017   |\n",
      "-------------------------------------------------------------\n",
      "Score: 9255.75 out of 11651.25\t(79.43997425168973%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "79.43997425168973"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_rel = relationModel.predict(X_test)\n",
    "pred_neu = neutralModel.predict(X_test)\n",
    "pred_val = valenceModel.predict(X_test)\n",
    "\n",
    "pred = [3 if pred_rel[i] == 3 else (2 if pred_neu[i] == 2 else (1 if pred_val[i] == 1 else 0)) for i in range(0, len(X_test))]\n",
    "        \n",
    "predicted = [LABELS[int(a)] for a in pred]\n",
    "actual = [LABELS[int(a)] for a in y_test]\n",
    "report_score(actual,predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
